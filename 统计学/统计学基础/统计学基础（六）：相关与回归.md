[TOC]

之前的统计量只描述单个变量，现在我们来学习一些可以说明**变量之间关系的统计量**。
<br/>




## 6.1 数据类型

### 6.1.1 单变量数据
&emsp;&emsp;单个变量的频数或概率。**例如**天晴时数 **，** 音乐会听众人数。
<center><b>表6-1 天晴时数表</b></center>

<center>
    <table align='center' border='1' width = '100px'>
      <tr>
        <th width='200px'> 天晴时数（小时） </th>
        <td> 1.9 </td>
        <td> 2.5 </td>
        <td> 3.2 </td>
        <td> 3.8 </td>
        <td> 4.7 </td>
        <td> 5.5 </td>
        <td> 5.9 </td>
        <td> 7.2 </td>
      </tr>
    </table>
</center>
<br/>

<center><b>表6-2 音乐会听众人数表</b></center>

<center>
    <table align='center' border='1' width = '100px'>
      <tr>
        <th width='200px'> 音乐会听众人数（百人） </th>
        <td> 22 </td>
        <td> 33 </td>
        <td> 30 </td>
        <td> 42 </td>
        <td> 38 </td>
        <td> 49 </td>
        <td> 42 </td>
        <td> 55 </td>
      </tr>
    </table>
</center>


<br/>

### 6.1.2 二变量数据
&emsp;&emsp;存在两个变量数值，若可以用一个变量来解释另一个变量，那么这个变量被称为自变量，另一个变量则称为因变量。**例如**音乐会听众人数**与**天晴时数。
<center><b>表6-3 音乐会听众人数与天晴时数表</b></center>

<center>
    <table align='center' border='1' width = '100px'>
      <tr>
        <th width='200px'> 天晴时数（小时） </th>
        <td> 1.9 </td>
        <td> 2.5 </td>
        <td> 3.2 </td>
        <td> 3.8 </td>
        <td> 4.7 </td>
        <td> 5.5 </td>
        <td> 5.9 </td>
        <td> 7.2 </td>
      </tr>
      <tr>
        <th> 音乐会听众人数（百人） </th>
        <td> 22 </td>
        <td> 33 </td>
        <td> 30 </td>
        <td> 42 </td>
        <td> 38 </td>
        <td> 49 </td>
        <td> 42 </td>
        <td> 55 </td>
      </tr>
    </table>
</center>
<br/>
<br/>



## 6.2 相关性

&emsp;&emsp;**变量之间的数学关系。**
&emsp;&emsp;对于二变量数据，我们可以使用散点图可视化数据，观察数据点的分布情况。

### 6.2.1 线性相关
&emsp;&emsp;**变量之间存在明显的线性关系。**
&emsp;&emsp;**正线性相关**：数据点呈直线分布，且y随x的增大而增大。

![正线性相关](C:\Users\11312_000\AppData\Roaming\Typora\typora-user-images\1554977188558.png)




&emsp;&emsp;**负线性相关**：数据点呈直线分布，且y随x的增大而减小。

![负线性相关](C:\Users\11312_000\AppData\Roaming\Typora\typora-user-images\1554977202290.png)





### 6.2.2 非线性相关
&emsp;&emsp;**变量之间存在明显的关系，但是不是线性。**
<br/>

### 6.2.3 不相关
&emsp;&emsp;**变量之间不存在明显的关系，为随机模式。**
**数据点呈随机分布**

![不相关](C:\Users\11312_000\AppData\Roaming\Typora\typora-user-images\1554977214437.png)

<br/>


## 6.3 相关性与因果性
&emsp;&emsp;相关性指变量间的**数量**关系。
&emsp;&emsp;因果性指变量间的**逻辑**关系。
$$
相关性\nRightarrow因果性 \\ 
因果性\Rightarrow相关性
$$



例如：防晒霜销量与花粉量正线性相关。

分析：并不能说明花粉量增多直接导致防晒霜销量提高，极有可能是花粉量增大表明天气晴朗，而天气晴朗，人们外出游行需要涂抹更多的防晒霜，因此防晒霜销量增加。也就是说晴朗的好天气导致花粉量增多和防晒霜销量提高，而花粉量和防晒霜销量并无直接因果关系。
$$
防晒霜销量与花粉量正线性相关\nRightarrow花粉量影响防晒霜销量 \\
天气影响花粉量\Rightarrow花粉量与天气正相关 \\
天气影响防晒霜销量\Rightarrow防晒霜销量与天气正相关
$$
<br/>


## 6.4 拟合

### 6.4.1 线性拟合 
$$
\\ （误差平方和）SSE = \sum(y-y_i)^2
\\ （回归线）\hat{y} = ax+b
$$
我们以SSE（误差平方和）为损失函数，在数学上，我们可以直接使用最小二乘法计算a（斜率），b（截距）。
<br/>

### 6.4.2 最小二乘法的数学公式

通过应用，掌握最小二乘法的使用。
$$
a = \frac{\sum(x_i-E(x)(y_i-E(y)))}{\sum(x_i-E(x))^2} 
\\ = \frac{E(xy)-E(x)E(y)}{E(x^2)-E^2(x)} 
\\ = \frac{Cov(x,y)}{Var(x)}
\\ b = E(y) - a*E(x)
$$
<br/>

### 6.4.3 最小二乘法的数学证明

感兴趣的同学，可手动推导一番公式。
$$
a = \frac{\sum(x_i-E(x)(y_i-E(y)))}{\sum(x_i-E(x))^2}
 = \frac{\sum(x_iy_i-x_iE(y)-E(x)y_i+E(x)E(y))}{\sum(x_i^2-2x_iE(x)+E^2(x))}
\\ = \frac{E(xy)-E(x)E(y)-E(x)E(y)+E(x)E(y)}{E(x^2)-2E^2(x)+E^2(x)} = \frac{E(xy)-E(x)E(y)}{E(x^2)-E^2(x)} 
\\ = \frac{Cov(x,y)}{Var(x)}
\\ \because \quad \hat{y} = ax+b \quad经过点(E(x), E(y))
\\ \therefore \quad b = E(y) - a*E(x)
$$



### 6.4.4 最小二乘法的应用

**根据天晴时数，预测音乐会听众人数。**

<center><b>表6-3 音乐会听众人数与天晴时数表</b></center>

<center>
    <table align='center' border='1' width = '100px'>
      <tr>
        <th width='200px'> 天晴时数（小时）&nbsp; x &nbsp; </th>
        <td> 1.9 </td>
        <td> 2.5 </td>
        <td> 3.2 </td>
        <td> 3.8 </td>
        <td> 4.7 </td>
        <td> 5.5 </td>
        <td> 5.9 </td>
        <td> 7.2 </td>
      </tr>
      <tr>
        <th>音乐会听众人数（百人）&nbsp; y &nbsp;  </th>
        <td> 22 </td>
        <td> 33 </td>
        <td> 30 </td>
        <td> 42 </td>
        <td> 38 </td>
        <td> 49 </td>
        <td> 42 </td>
        <td> 55 </td>
      </tr>
    </table>
</center>
<br/>
$$
E(x) = \frac{\sum(x_i)}{n} = \frac{1.9+2.5+3.2+3.8+4.7+5.5+5.9+7.2}{8} = 4.3375
\\
\\ 同理 \quad E(y) = 38.875, \quad E(xy) = 183.975, \quad E(x^2) = 21.69125
\\ \therefore a = \frac{E(xy)-E(x)E(y)}{E(x^2)-E^2(x)}  = \frac{183.975-4.3375*38.875}{21.69125-(4.3375)^2} = 5.336
\\ \quad b = E(y) - a*E(x) = 38.875 - 5.336*4.3375 = 15.73
\\ \therefore \quad \hat{y} = 5.336x+15.73
$$

拟合结果如下图所示：


![1554988026903](C:\Users\11312_000\AppData\Roaming\Typora\typora-user-images\1554988026903.png)

### 6.4.5 相关系数
相关系数描述了各个数据点与直线的偏离程度，用于度量回归线与数据的拟合度，通常用字母**r**表示。

$$
r \in [-1,1]
\\ r = 1，完全正线性相关；
\\ r = -1，完全负线性相关；
\\ r = 0，不存在相关性；
$$

$s_x, s_y是样本方差，我们使用无偏的样本方差计算相关系数r。$

$$
s_x = \frac{\sum(x_i-E(x)^2}{n-1},\quad s_y = \frac{\sum(y_i-E(y)^2}{n-1}
\\ r = \frac{as_x}{s_y}
\\ 
\\
$$

现在我们来求$\hat{y} = 5.336x+15.73$与原数据的相关系数
$$
a = 5.336
\\ s_x = \frac{\sum(x_i-E(x)^2}{n-1} = \frac{(1.9-4.375)^2+(2.5-4.375)^2+(3.2-4.375)^2+(3.8-4.375)^2+(4.7-4.375)^2+(5.5-4.375)^2+(5.9-4.375)^2+(7.2-4.375)^2}{8-1} = 
\\ 同理 \quad s_y = 
\\ \therefore r = \frac{as_x}{s_y} = =
$$



### 6.4.6 线性拟合的再次应用






注意：只有在处于数据范围以内时，我们才能自行给出结论。

有影响观察结果和异常值
有影响观察结果是在水平方向上远离数据的点（从数据看）；
异常值是远偏离回归线的点（从拟合效果看）。





相关代码





![Practical Definition of Machine Learning](E:\学习笔记\Datawhale\统计学\统计学基础\统计学基础（六）：相关与回归\Practical Definition of Machine Learning.png)



![Practical Definition of Machine Learning](E:\学习笔记\Datawhale\统计学\统计学基础\img\统计学基础(六)：相关与回归\Practical Definition of Machine Learning.png)



![Practical Definition of Machine Learning](E:\学习笔记\Datawhale\统计学\统计学基础\img\统计学基础(六)：相关与回归\Practical Definition of Machine Learning.png)


E:\学习笔记\Datawhale\统计学\统计学基础\img\统计学基础（六）：相关与回归



参考：

《深入浅出统计学》

可汗学院公开课：统计学 http://open.163.com/special/Khan/khstatistics.html

