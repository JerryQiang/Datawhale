【每日一问】
L1 L2 正则化的区别，为什么 L1 产生稀疏矩阵，L2 可以防止过拟合?

正则化在机器学习的应用是做为模型参数的惩罚项，用于防止模型过于复杂（过拟合），达到更好的拟合效果。
L1是线性惩罚，L2是平方惩罚。
L1对每个参数拥有等价的惩罚效果，所以趋向于每个参数大致相等，会产生接近于0的稀疏权重矩阵；
L2偏向于相差大的权重系数，会在模型过拟合的情况下，增加权重系数大的值，减少权重系数小的值，降低模型的过拟合程度。
其实正则化都能降低模型过拟合程度，L1偏向于取均值（参数大致相同），L2偏向于取差值（参数相差大）。